{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6735e0-9d2d-4957-a88a-a520bdc4f377",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognizer - Simple Neural Network Classification\n",
    "\n",
    "**Authors: Clement, Calvin, Tilova**\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the second notebook by **Tequila Chicas**! We will be classifying images of hand written numbers to their corresponding digits. This project follows the guidelines and uses the data set provide from the Kaggle Competition [here](https://www.kaggle.com/competitions/digit-recognizer/overview). \n",
    "\n",
    "## Introduction  \n",
    "\n",
    "In this notebook we will be fitting the dataset in a simple neural network to see how well we can predict the digits of the MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e87ed1-9831-4c4c-8676-59ac62889490",
   "metadata": {},
   "source": [
    "<a id = 'toc'></a>\n",
    "    \n",
    "## Table of Contents\n",
    "---\n",
    "1. [Simple Neural Network](#simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f3c5d-4e95-49bb-96b4-3323428d4c3a",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea50e368-24e3-485d-a786-9798f850b062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train_Test_Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# ignores the filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eae939-7fcd-4909-a5fe-8ddc8a26dff9",
   "metadata": {},
   "source": [
    "<a id = 'simple'></a>\n",
    "### 1. Simple Neural Network\n",
    "---\n",
    "Loading the test and train set CSVs files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a7d56f0-856b-469b-81cc-999fe80a3334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cbd2c-551e-4443-ac62-8a6b2d612781",
   "metadata": {},
   "source": [
    "We need to set our independent (X) and dependent (y) variables as `numpy arrays` from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88b6f43-3a51-458a-9d97-0d613afaf38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train.iloc[:, 1:].to_numpy()\n",
    "y = df_train.iloc[:, 0].to_numpy()\n",
    "\n",
    "# sanity check\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f7d04-5111-4feb-bde0-9d5851db193c",
   "metadata": {},
   "source": [
    "We will perform a **train_test_split()** to split our dataset into train and validation sets.\n",
    "- Validation size of 25% of the data.\n",
    "- Stratify=y to make sure distribution of the classes remain the same in both training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88dce51b-7e1e-42c3-ad70-236e6944d053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31500, 784), (31500,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d4afe-4c59-43d1-a8f7-de1fd9ff28f0",
   "metadata": {},
   "source": [
    "We can start by implementing a simple `linear` network.\n",
    "- Since it's linear, we would obtain better results when scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "522e4ca3-6570-493c-b913-c19b6175863a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate standard scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fit and transform training\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# ONLY transform X_val\n",
    "X_test = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef78205-6ad4-481d-9320-61c3a5708aeb",
   "metadata": {},
   "source": [
    "Now we need to convert the 1-D `arrays` into torch `tensors`\n",
    "- Using float32 to cut down memory usage\n",
    "- Using torch.long for classification labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f59cd247-d25c-4573-b972-010c423e6cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31500, 784]) torch.Size([31500]) torch.Size([10500, 784]) torch.Size([10500])\n"
     ]
    }
   ],
   "source": [
    "# Independent Variables\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "# Dependent Variable\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Sanity Check\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53a452c1-b839-474d-9f9c-e6a6fc57991f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=100, bias=True)\n",
       "  (1): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple neural net layers\n",
    "simple_neural_net = nn.Sequential(\n",
    "    nn.Linear(784, 100),\n",
    "    nn.Linear(100, 10)\n",
    "    )\n",
    "simple_neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d2f35b68-fa74-4313-b30d-6ff2924982d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "single_row = X_train[[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "14bafbc2-91fc-4a9a-aa4a-37693c18de47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0877, 0.0890, 0.0941, 0.0933, 0.0747, 0.1531, 0.0928, 0.0652, 0.1357,\n",
      "         0.1144]], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "output_logit_values = simple_neural_net(single_row)\n",
    "output_values = nn.functional.softmax(output_logit_values, dim=1)\n",
    "print(output_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f177c4b-5b6c-4591-a9d4-afbcf0a954ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
