{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b6735e0-9d2d-4957-a88a-a520bdc4f377",
   "metadata": {},
   "source": [
    "# MNIST Digit Recognizer - Simple Neural Network Classification\n",
    "\n",
    "**Authors: Clement, Calvin, Tilova**\n",
    "\n",
    "---\n",
    "\n",
    "Welcome to the second notebook by **Tequila Chicas**! We will be classifying images of hand written numbers to their corresponding digits. This project follows the guidelines and uses the data set provide from the Kaggle Competition [here](https://www.kaggle.com/competitions/digit-recognizer/overview). \n",
    "\n",
    "## Introduction  \n",
    "\n",
    "In this notebook we will be fitting the dataset in a simple neural network to see how well we can predict the digits of the MNIST Dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e87ed1-9831-4c4c-8676-59ac62889490",
   "metadata": {},
   "source": [
    "<a id = 'toc'></a>\n",
    "    \n",
    "## Table of Contents\n",
    "---\n",
    "1. [Simple Neural Network](#simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71f3c5d-4e95-49bb-96b4-3323428d4c3a",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea50e368-24e3-485d-a786-9798f850b062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Train_Test_Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Progress bar from tqdm\n",
    "from tqdm.notebook import tnrange\n",
    "\n",
    "# ignores the filter warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eae939-7fcd-4909-a5fe-8ddc8a26dff9",
   "metadata": {},
   "source": [
    "<a id = 'simple'></a>\n",
    "### 1. Simple Neural Network\n",
    "---\n",
    "Loading the test and train set CSVs files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a7d56f0-856b-469b-81cc-999fe80a3334",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((42000, 785), (28000, 784))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021cbd2c-551e-4443-ac62-8a6b2d612781",
   "metadata": {},
   "source": [
    "We need to set our independent (X) and dependent (y) variables as `numpy arrays` from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d88b6f43-3a51-458a-9d97-0d613afaf38f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784) (42000,)\n"
     ]
    }
   ],
   "source": [
    "X = df_train.iloc[:, 1:].to_numpy()\n",
    "y = df_train.iloc[:, 0].to_numpy()\n",
    "\n",
    "# sanity check\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384f7d04-5111-4feb-bde0-9d5851db193c",
   "metadata": {},
   "source": [
    "We will perform a **train_test_split()** to split our dataset into train and validation sets.\n",
    "- Validation size of 25% of the data.\n",
    "- Stratify=y to make sure distribution of the classes remain the same in both training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88dce51b-7e1e-42c3-ad70-236e6944d053",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31500, 784), (31500,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, stratify=y)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95d4afe-4c59-43d1-a8f7-de1fd9ff28f0",
   "metadata": {},
   "source": [
    "We can start by implementing a simple `linear` network.\n",
    "- Since it's linear, we would obtain better results when scaling the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522e4ca3-6570-493c-b913-c19b6175863a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# instantiate standard scaler\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fit and transform training\n",
    "X_train = ss.fit_transform(X_train)\n",
    "\n",
    "# ONLY transform X_val\n",
    "X_test = ss.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef78205-6ad4-481d-9320-61c3a5708aeb",
   "metadata": {},
   "source": [
    "Now we need to convert the 1-D `arrays` into torch `tensors`\n",
    "- Using float32 to cut down memory usage\n",
    "- Using torch.long for classification labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f59cd247-d25c-4573-b972-010c423e6cfa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([31500, 784]) torch.Size([31500]) torch.Size([10500, 784]) torch.Size([10500])\n"
     ]
    }
   ],
   "source": [
    "# Independent Variables\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "\n",
    "# Dependent Variable\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "\n",
    "# Sanity Check\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53a452c1-b839-474d-9f9c-e6a6fc57991f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=784, out_features=200, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=200, out_features=50, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple neural net layers\n",
    "simple_neural_net = nn.Sequential(\n",
    "    nn.Linear(784, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 50),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(50, 10)\n",
    "    )\n",
    "simple_neural_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2f35b68-fa74-4313-b30d-6ff2924982d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old loss: 2.2717764377593994\n",
      "New loss: 2.192401647567749\n"
     ]
    }
   ],
   "source": [
    "# Creating a single row\n",
    "single_row = X_train[[0], :]\n",
    "single_target = y_train[[0]]\n",
    "\n",
    "\n",
    "# Instantiate Optimizer\n",
    "optimizer = torch.optim.SGD(simple_neural_net.parameters(), lr=0.01)\n",
    "\n",
    "#### Forward pass ####\n",
    "output_values = simple_neural_net(single_row)\n",
    "\n",
    "# Cross Entropy Loss\n",
    "cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "loss = cross_entropy_loss(output_values, single_target)\n",
    "\n",
    "#### Backward pass ####\n",
    "loss.backward()\n",
    "\n",
    "# Update Weights\n",
    "optimizer.step()\n",
    "\n",
    "# New Outputs\n",
    "new_output = simple_neural_net(single_row)\n",
    "new_loss = cross_entropy_loss(new_output, single_target)\n",
    "\n",
    "# Comparing old and new loss\n",
    "print(f\"Old loss: {loss}\\nNew loss: {new_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e313aa-a481-49f1-9cff-1353ac75df82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da7807b-1a7c-4a8b-b88d-a43f43f1ddcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1aa977-b273-41d2-86ec-2a817fc15408",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4bf9e-1506-4cc8-9ba8-e0af58377750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912e0b68-d689-45c2-9efd-ea76ed0f3dc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3444a28-789c-4f20-9f08-c85278d63a69",
   "metadata": {},
   "source": [
    "Someone plz explain this what `__init__` does again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2349e195-570a-4640-9cdf-50f02153a870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    \"\"\"Basic multi-layer architecture.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Define the main components of the network\"\"\"\n",
    "        super(SimpleNN, self).__init__()\n",
    "        \n",
    "        self.layer_1 = nn.Linear(784, 100) # transition from input into hidden layer\n",
    "        self.activation_1 = nn.ReLU()   # Activation function\n",
    "        self.layer_2 = nn.Linear(100, 10)  # transition from hidden layer into output\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform forward pass.\"\"\"\n",
    "\n",
    "        # pass through the layers\n",
    "        hidden_1 = self.activation_1(self.layer_1(x))\n",
    "        output = self.layer_2(hidden_1)\n",
    "\n",
    "        # return output\n",
    "        return output\n",
    "\n",
    "    def predict(self, x):\n",
    "        '''\n",
    "        The class based interface allows you\n",
    "        add your own functionality, like a familiar\n",
    "        .predict method we all know and love\n",
    "        '''\n",
    "\n",
    "        # Predict class probabilities\n",
    "        predictions = self.forward(x)\n",
    "\n",
    "        # Find highest class prediction, notice we don't need to convert to\n",
    "        # probabilities to do hard predictions, we can simply choose the\n",
    "        # highest values\n",
    "        hard_class_predictions = torch.argmax(predictions, dim=1)\n",
    "\n",
    "        return hard_class_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32169d58-0992-48a3-8f6a-b4cdb1febc77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Instantiate the model, the loss criterion, and the optimizer\n",
    "NN_model = SimpleNN()\n",
    "\n",
    "cross_entropy_loss = nn.CrossEntropyLoss() # this includes the softmax\n",
    "optimizer = torch.optim.SGD(NN_model.parameters(), lr=.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b652540-ffb4-45f4-a893-521339b8a26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### COMMON PYTORCH RECIPE FOR TRAINING A NETWORK ###\n",
    "\n",
    "\n",
    "# Now run for 100 epochs\n",
    "for epoch in tnrange(100, desc=\"Total epochs: \"):\n",
    "\n",
    "    # Clear gradients (pytorch accumulates gradients by default)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate outputs\n",
    "    output_values = NN_model(X_train)\n",
    "\n",
    "    # Calculate loss\n",
    "    loss = cross_entropy_loss(output_values, y_train)\n",
    "\n",
    "    # Backpropagation & weight adjustment\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f\"Optimization ended successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f361af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "binary_classification = NN_model.predict(X_train)\n",
    "\n",
    "# Calculate the score on the test set\n",
    "accuracy = accuracy_score(y_train, binary_classification)\n",
    "print(f\"Accuracy score on train set: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ba3a4-fd43-41ce-aa0d-7d2dba34eb5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "binary_classification = NN_model.predict(X_val)\n",
    "\n",
    "# Calculate the score on the test set\n",
    "accuracy = accuracy_score(y_val, binary_classification)\n",
    "print(f\"Accuracy score on test set: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30c2195",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd2c8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
